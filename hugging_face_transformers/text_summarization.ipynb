{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    " Description: Text summarization using BART"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Import libraries\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/james/Coding/Neural-Networks/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load pre-trained model\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Define article to summarize\n",
    "ARTICLE_TO_SUMMARIZE = \"\"\"PG&E stated it scheduled the blackouts in response to\n",
    "forecasts for high winds amid dry conditions. The aim is to reduce the\n",
    "risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by\n",
    "the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
    "print(\"ARTICLE TO SUMMARIZE:\", ARTICLE_TO_SUMMARIZE)\n",
    "inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors=\"pt\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ARTICLE TO SUMMARIZE: PG&E stated it scheduled the blackouts in response to\n",
      "forecasts for high winds amid dry conditions. The aim is to reduce the\n",
      "risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by\n",
      "the shutoffs which were expected to last through at least midday tomorrow.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=2, min_length=0, max_length=20)\n",
    "summary_text = tokenizer.batch_decode(\n",
    "    summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(\"SUMMARY OF ARTICLE:\", summary_text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SUMMARY OF ARTICLE: PG&E scheduled the blackouts in response to high winds amid dry conditions. The\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=2, min_length=0, max_length=30)\n",
    "summary_text = tokenizer.batch_decode(\n",
    "    summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(\"SUMMARY OF ARTICLE:\", summary_text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SUMMARY OF ARTICLE: PG&E scheduled the blackouts in response to high winds amid dry conditions. The aim is to reduce the risk of wildfires.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 }
}